{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd042a5aeadb626e9fab306cc11d7880aebf2727abe172c58f891e2dedde345f7e9",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "9dd2a7f0e8d56c01bd8b1f02272b074a14c4c692fa43bd87c3dd10ef9416327f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b6af9d28f609>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# config data saved to config.py - change values as instructed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpostgresUname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpostgresPword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpostgresHost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpostgresDb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "# dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# config data saved to config.py - change values as instructed\n",
    "# from config import postgresUname,postgresPword,postgresHost,postgresDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define filename\n",
    "house_prices_file = \"all_perth_310121.csv\"\n",
    "\n",
    "# assign filepath\n",
    "house_prices_path = os.path.join(\"resources\", house_prices_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data\n",
    "house_prices_df = pd.read_csv(house_prices_path)\n",
    "\n",
    "# inspect data\n",
    "house_prices_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect data types\n",
    "house_prices_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform datatype to date\n",
    "house_prices_df[\"DATE_SOLD\"] = pd.to_datetime(house_prices_df[\"DATE_SOLD\"])\n",
    "\n",
    "# transform date to unix\n",
    "house_prices_df[\"DATE_SOLD_UNIX\"] = (house_prices_df[\"DATE_SOLD\"] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "\n",
    "# confirm dates are unix format\n",
    "house_prices_df[\"DATE_SOLD_UNIX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find house duplicates\n",
    "house_prices_df.ADDRESS.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare sale info dataframe\n",
    "sale_info_df = house_prices_df[['PRICE', 'DATE_SOLD_UNIX']]\n",
    "sale_info_df = sale_info_df.rename(columns={'PRICE':'price','DATE_SOLD_UNIX':'date'})\n",
    "sale_info_df['sale_id'] = sale_info_df.index + 100001\n",
    "sale_info_df = sale_info_df[['sale_id','price','date']]\n",
    "\n",
    "sale_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare location info dataframe\n",
    "location_info_df = house_prices_df[['ADDRESS','SUBURB','POSTCODE','LATITUDE','LONGITUDE','CBD_DIST','NEAREST_STN','NEAREST_STN_DIST','NEAREST_SCH','NEAREST_SCH_DIST','NEAREST_SCH_RANK']]\n",
    "location_info_df = location_info_df.rename(columns={'ADDRESS':'address','SUBURB':'suburb','POSTCODE':'postcode','LATITUDE':'latitude','LONGITUDE':'longitude','CBD_DIST':'cbd_dist', 'NEAREST_STN':'nearest_stn','NEAREST_STN_DIST':'nearest_stn_dist','NEAREST_SCH':'nearest_sch','NEAREST_SCH_DIST':'nearest_sch_dist','NEAREST_SCH_RANK':'nearest_sch_rank'})\n",
    "location_info_df = location_info_df.drop_duplicates(subset='address')\n",
    "location_info_df = location_info_df.reset_index()\n",
    "location_info_df['house_id'] = location_info_df.index + 200001\n",
    "location_info_df = location_info_df[['house_id','address','suburb','postcode','latitude','longitude','cbd_dist','nearest_stn','nearest_stn_dist','nearest_sch','nearest_sch_dist','nearest_sch_rank']]\n",
    "\n",
    "location_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare house info dataframe\n",
    "house_df = house_prices_df[['ADDRESS','SUBURB','BEDROOMS','BATHROOMS','GARAGE','LAND_AREA','FLOOR_AREA','BUILD_YEAR']]\n",
    "house_df = house_df.rename(columns={'ADDRESS':'address','SUBURB':'suburb','BEDROOMS':'bedrooms','BATHROOMS':'bathrooms','GARAGE':'garage','LAND_AREA':'land_area','FLOOR_AREA':'floor_area','BUILD_YEAR':'build_year'})\n",
    "house_df['sale_id'] = house_df.index + 100001\n",
    "house_df = house_df[['sale_id','address','suburb','bedrooms','bathrooms','garage','land_area','floor_area','build_year']]\n",
    "\n",
    "# merge location info and house dataframes\n",
    "house_info_df = pd.DataFrame.merge(house_df,location_info_df,how=\"right\",on=[\"address\", \"suburb\"])\n",
    "house_info_df = house_info_df[['sale_id','house_id','bedrooms','bathrooms','garage','land_area','floor_area','build_year']]\n",
    "house_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection string using config data\n",
    "connection = f'{postgresUname}:{postgresPword}@{postgresHost}/{postgresDb}'\n",
    "engine = create_engine(f'postgresql://{connection}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm tables\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sale info data\n",
    "sale_info_df.to_sql(name='sale_info', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load location info data\n",
    "location_info_df.to_sql(name='location_info', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load house info data\n",
    "house_info_df.to_sql(name='house_info', con=engine, if_exists='append', index=False)"
   ]
  }
 ]
}